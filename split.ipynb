{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d72371-8315-45ed-88b1-7137b228ab43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import collections\n",
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from text_utils import generate_text_artifacts\n",
    "from image_utils import load_image\n",
    "from config import subset, batch_size, max_length, vocabulary_size, train_split\n",
    "from config import WANDB_PROJECT, WANDB_ENTITY\n",
    "from utils import save_to_pickle, load_from_pickle\n",
    "import pandas as pd\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1865dc58-f2a9-4f23-abe2-960f089a48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ma-sh0ts\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/fauxvo-faux/image_captioning/runs/37o2dmxt\" target=\"_blank\">log-test-train-split</a></strong> to <a href=\"https://wandb.ai/fauxvo-faux/image_captioning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=WANDB_PROJECT,\n",
    "                 entity=WANDB_ENTITY, name=\"log-test-train-split\", job_type=\"data_process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c0c4aa-feaf-4ec5-9193-029d8b52db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact images:latest, 12867.46MB. 82783 files... Done. 0:0:0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact image_caption_table:latest, 951.74MB. 6001 files... Done. 0:0:0\n"
     ]
    }
   ],
   "source": [
    "images_art = run.use_artifact(\"images:latest\")\n",
    "images_path = images_art.download()\n",
    "img_cap_table = run.use_artifact(\n",
    "    \"image_caption_table:latest\").get(\"img_cap_table\")\n",
    "captions = img_cap_table.get_column(\"caption\")\n",
    "img_names = img_cap_table.get_column(\"name\")\n",
    "\n",
    "img_name_vector = [os.path.join(images_path, img_name)\n",
    "                   for img_name in img_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dcc491-fec2-426e-8eb3-e37214ff64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_dataset = tf.data.Dataset.from_tensor_slices(captions)\n",
    "# cap vecotr contains each sentence as max_length where the word position index is the vocab index\n",
    "_, cap_vector, _, _ = generate_text_artifacts(\n",
    "    caption_dataset, max_length=max_length, vocabulary_size=vocabulary_size, return_mapping=False)\n",
    "\n",
    "img_to_cap_vector = collections.defaultdict(list)\n",
    "for img, cap in zip(img_name_vector, cap_vector):\n",
    "    img_to_cap_vector[img].append(cap)\n",
    "\n",
    "# Create training and validation sets using an 80-20 split randomly.\n",
    "img_keys = list(img_to_cap_vector.keys())\n",
    "random.shuffle(img_keys)\n",
    "\n",
    "slice_index = int(len(img_keys)*train_split)\n",
    "img_name_train_keys, img_name_val_keys = img_keys[:\n",
    "                                                  slice_index], img_keys[slice_index:]\n",
    "\n",
    "img_name_train = []\n",
    "cap_train = []\n",
    "for img_path in img_name_train_keys:\n",
    "    train_img_name = os.path.basename(img_path)\n",
    "    train_caps = img_to_cap_vector[img_path]\n",
    "    capt_len = len(train_caps)\n",
    "    img_name_train.extend([train_img_name] * capt_len)\n",
    "    cap_train.extend(train_caps)\n",
    "\n",
    "img_name_val = []\n",
    "cap_val = []\n",
    "for img_path in img_name_val_keys:\n",
    "    val_img_name = os.path.basename(img_path)\n",
    "    val_caps = img_to_cap_vector[img_path]\n",
    "    capv_len = len(val_caps)\n",
    "    img_name_val.extend([val_img_name] * capv_len)\n",
    "    cap_val.extend(val_caps)\n",
    "\n",
    "split_art_dir = os.path.join(\".\", \"split_data\")\n",
    "if not os.path.exists(split_art_dir):\n",
    "    os.makedirs(split_art_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c76a35-8ad2-4cff-8d1a-436042f93e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(img_name_train, os.path.join(\n",
    "    split_art_dir, \"img_name_train.pkl\"))\n",
    "save_to_pickle(cap_train, os.path.join(split_art_dir, \"cap_train.pkl\"))\n",
    "save_to_pickle(img_name_val, os.path.join(\n",
    "    split_art_dir, \"img_name_val.pkl\"))\n",
    "save_to_pickle(cap_val, os.path.join(\n",
    "    split_art_dir, \"cap_val.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82a9271-fe30-4745-b98b-084c9cdb298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\split_data)... Done. 0.1s\n"
     ]
    }
   ],
   "source": [
    "split_art = wandb.Artifact(name=\"split\", type=\"dataset\")\n",
    "split_art.add_dir(split_art_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f00e308-1253-4343-b00b-84a76979385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wandb_imgs = [wandb.Image(os.path.join(images_path, path))\n",
    "                    for path in img_name_train]\n",
    "val_wandb_imgs = [wandb.Image(os.path.join(images_path, path))\n",
    "                  for path in img_name_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f875b91b-4a03-479f-9c87-3e74a73a7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24012it [03:55, 102.11it/s]\n",
      "6001it [01:00, 98.99it/s] \n"
     ]
    }
   ],
   "source": [
    "train_img_cap_table =  wandb.Table(columns=[\"name\", \"image\", *[f\"word_index_{i}\" for i in range(max_length)]])\n",
    "for name, image, caption in tqdm(zip(img_name_train, train_wandb_imgs, cap_train)):\n",
    "    train_img_cap_table.add_data(name, image, *[cap_index.numpy() for cap_index in caption])\n",
    "\n",
    "val_img_cap_table = wandb.Table(columns=[\"name\", \"image\", *[f\"word_index_{i}\" for i in range(max_length)]])\n",
    "for name, image, caption in tqdm(zip(img_name_val, val_wandb_imgs, cap_val)):\n",
    "    val_img_cap_table.add_data(name, image, *[cap_index.numpy() for cap_index in caption])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264b604a-a946-4765-bb9c-61b3f18dc7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_cap_table.set_fk(\"name\", img_cap_table, \"name\")\n",
    "val_img_cap_table.set_fk(\"name\", img_cap_table, \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38c6963-d794-461e-944e-80957ee1f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ManifestEntry digest: mZ/rlU22nHZHBE95Ue54RQ==>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_art.add(train_img_cap_table, \"train_img_cap_table\")\n",
    "split_art.add(val_img_cap_table, \"val_img_cap_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a10040-78f6-4787-bf7e-9e91c183e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15820... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 980.25MB of 980.25MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 2 media file(s), 6008 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">log-test-train-split</strong>: <a href=\"https://wandb.ai/fauxvo-faux/image_captioning/runs/37o2dmxt\" target=\"_blank\">https://wandb.ai/fauxvo-faux/image_captioning/runs/37o2dmxt</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220301_143318-37o2dmxt\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.log({\n",
    "    \"train_img_cap_table\": train_img_cap_table,\n",
    "    \"val_img_cap_table\": val_img_cap_table\n",
    "})\n",
    "run.log_artifact(split_art)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2143ee4-60f9-4948-8950-727bd7f145ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
